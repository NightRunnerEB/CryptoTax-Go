// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.30.0
// source: historical_prices.sql

package db

import (
	"context"

	"github.com/jackc/pgx/v5/pgtype"
)

const getHistoricalPrice = `-- name: GetHistoricalPrice :one
SELECT coin_id, bucket_start_utc, price_usd, granularity_seconds, fetched_at
FROM historical_prices
WHERE coin_id = $1
  AND bucket_start_utc = $2
`

type GetHistoricalPriceParams struct {
	CoinID         string             `json:"coinId"`
	BucketStartUtc pgtype.Timestamptz `json:"bucketStartUtc"`
}

func (q *Queries) GetHistoricalPrice(ctx context.Context, arg GetHistoricalPriceParams) (HistoricalPrice, error) {
	row := q.db.QueryRow(ctx, getHistoricalPrice, arg.CoinID, arg.BucketStartUtc)
	var i HistoricalPrice
	err := row.Scan(
		&i.CoinID,
		&i.BucketStartUtc,
		&i.PriceUsd,
		&i.GranularitySeconds,
		&i.FetchedAt,
	)
	return i, err
}

const getHistoricalPricesBatch = `-- name: GetHistoricalPricesBatch :many
WITH keys AS (
  SELECT c.coin_id, b.bucket_start_utc, c.ord
  FROM unnest($1::text[]) WITH ORDINALITY AS c(coin_id, ord)
  JOIN unnest($2::timestamptz[]) WITH ORDINALITY AS b(bucket_start_utc, ord)
    USING (ord)
)
SELECT
  k.coin_id::text                        AS coin_id,
  k.bucket_start_utc::timestamptz        AS bucket_start_utc,
  hp.price_usd                           AS price_usd,
  hp.granularity_seconds                 AS granularity_seconds,
  hp.fetched_at                          AS fetched_at
FROM keys k
LEFT JOIN historical_prices hp
  ON hp.coin_id = k.coin_id
 AND hp.bucket_start_utc = k.bucket_start_utc
ORDER BY k.ord
`

type GetHistoricalPricesBatchParams struct {
	Column1 []string             `json:"column1"`
	Column2 []pgtype.Timestamptz `json:"column2"`
}

type GetHistoricalPricesBatchRow struct {
	CoinID             string             `json:"coinId"`
	BucketStartUtc     pgtype.Timestamptz `json:"bucketStartUtc"`
	PriceUsd           pgtype.Numeric     `json:"priceUsd"`
	GranularitySeconds *int32             `json:"granularitySeconds"`
	FetchedAt          pgtype.Timestamptz `json:"fetchedAt"`
}

func (q *Queries) GetHistoricalPricesBatch(ctx context.Context, arg GetHistoricalPricesBatchParams) ([]GetHistoricalPricesBatchRow, error) {
	rows, err := q.db.Query(ctx, getHistoricalPricesBatch, arg.Column1, arg.Column2)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetHistoricalPricesBatchRow
	for rows.Next() {
		var i GetHistoricalPricesBatchRow
		if err := rows.Scan(
			&i.CoinID,
			&i.BucketStartUtc,
			&i.PriceUsd,
			&i.GranularitySeconds,
			&i.FetchedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const upsertHistoricalPrice = `-- name: UpsertHistoricalPrice :exec
INSERT INTO historical_prices (coin_id, bucket_start_utc, price_usd, granularity_seconds, fetched_at)
VALUES ($1, $2, $3, $4, now())
ON CONFLICT (coin_id, bucket_start_utc)
DO UPDATE SET
  price_usd = EXCLUDED.price_usd,
  granularity_seconds = EXCLUDED.granularity_seconds,
  fetched_at = now()
WHERE EXCLUDED.granularity_seconds < historical_prices.granularity_seconds
`

type UpsertHistoricalPriceParams struct {
	CoinID             string             `json:"coinId"`
	BucketStartUtc     pgtype.Timestamptz `json:"bucketStartUtc"`
	PriceUsd           pgtype.Numeric     `json:"priceUsd"`
	GranularitySeconds int32              `json:"granularitySeconds"`
}

func (q *Queries) UpsertHistoricalPrice(ctx context.Context, arg UpsertHistoricalPriceParams) error {
	_, err := q.db.Exec(ctx, upsertHistoricalPrice,
		arg.CoinID,
		arg.BucketStartUtc,
		arg.PriceUsd,
		arg.GranularitySeconds,
	)
	return err
}

const upsertHistoricalPricesBatch = `-- name: UpsertHistoricalPricesBatch :exec
WITH rows AS (
  SELECT
    c.coin_id,
    b.bucket_start_utc,
    p.price_usd,
    g.granularity_seconds
  FROM unnest($1::text[])        WITH ORDINALITY AS c(coin_id, ord)
  JOIN unnest($2::timestamptz[]) WITH ORDINALITY AS b(bucket_start_utc, ord) USING (ord)
  JOIN unnest($3::numeric[])     WITH ORDINALITY AS p(price_usd, ord) USING (ord)
  JOIN unnest($4::int4[])        WITH ORDINALITY AS g(granularity_seconds, ord) USING (ord)
)
INSERT INTO historical_prices (
  coin_id,
  bucket_start_utc,
  price_usd,
  granularity_seconds,
  fetched_at
)
SELECT
  coin_id,
  bucket_start_utc,
  price_usd,
  granularity_seconds,
  now()
FROM rows
ON CONFLICT (coin_id, bucket_start_utc)
DO UPDATE SET
  price_usd = EXCLUDED.price_usd,
  granularity_seconds = EXCLUDED.granularity_seconds,
  fetched_at = now()
WHERE EXCLUDED.granularity_seconds < historical_prices.granularity_seconds
`

type UpsertHistoricalPricesBatchParams struct {
	Column1 []string             `json:"column1"`
	Column2 []pgtype.Timestamptz `json:"column2"`
	Column3 []pgtype.Numeric     `json:"column3"`
	Column4 []int32              `json:"column4"`
}

func (q *Queries) UpsertHistoricalPricesBatch(ctx context.Context, arg UpsertHistoricalPricesBatchParams) error {
	_, err := q.db.Exec(ctx, upsertHistoricalPricesBatch,
		arg.Column1,
		arg.Column2,
		arg.Column3,
		arg.Column4,
	)
	return err
}
